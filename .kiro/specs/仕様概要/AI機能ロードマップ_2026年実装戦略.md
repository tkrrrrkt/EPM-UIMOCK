# AI機能ロードマップ：2026年実装戦略
## CCSDD EPMプロジェクトのAI統合ガイド

**作成日**: 2026年1月30日
**対象**: プロダクト全体、Phase 1-4 AI戦略
**参考**: `.kiro/specs/仕様検討/20260128_生成AI機能の機能検討のためのDeepReaserch結果`
**開発フレームワーク**: CCSDD (Contract-Centered Specification Driven Development)

---

## エグゼクティブサマリー

### 現在地
- ✅ **CCSDD基盤が整備済み**: Contracts-first、Multi-tenant、RLS対応
- ✅ **コア機能実装済み**: KPI Master、Dashboard、Meeting Minutes
- ✅ **市場調査完了**: Deep Research（外資大手5社、中堅5社、国内2社、BIツール5社）
- ❌ **AI統合レイヤーが未実装**: Semantic Layer、LLM Service、AI Entities（DB）

### 市場環境（2025-2026）
- **EPM×AI導入率**: 58%（2024年）→ 90%（2026年予測）
- **進化段階**: 予測AI → 生成AI → **エージェントAI（2026年の競争軸）**
- **トレンド**: 全ベンダーが「役割別AIエージェント」を発表
- **日本市場**: グローバルより15-20ポイント低い導入率だが、高い需要

### プロジェクトの戦略的機会
**グローバルベンダー（Oracle、SAP、Anaplan）との競争において、貴プロジェクトが勝つための3つの差別化ポイント:**

1. **日本語ネイティブ + FP&A特化の分析エージェント**
   → グローバル勢は日本語対応が限定的

2. **説明可能AI（Glass Box）**
   → J-SOX改正で監査証跡・根拠表示が必須化

3. **Excel互換性を保ちながらAI統合**
   → 既存Excel資産を活かしつつAI自動化

---

## Part 1: 市場分析サマリー

### 外資EPM大手5社のAI戦略（2024-2025）

| ベンダー | AI投資額 | 主力機能 | 差別化ポイント |
|---------|---------|---------|--------------|
| **Oracle EPM** | 不詳 | IPM Insights、PCM Agent | BYOML対応、セキュリティ |
| **SAP Analytics Cloud** | 不詳 | Joule | 11言語対応、Microsoft連携 |
| **Anaplan** | 約750億円 | CoPlanner、Finance Analyst Agent | $500M投資、ノーコード |
| **Workday Adaptive** | 不詳 | Intelligent Variance Analysis | **追加料金なし** |
| **OneStream** | 不詳 | SensibleAI Agents | 2017年からのML実績 |

**共通戦略**: 全社が「フルスタックAI」（予測・異常検知・NLQ・ナラティブ・エージェント）をカバー

### 国内ベンダー（Loglass、DIGGLE）の現状と野心

| 企業 | AI分野の投資 | Phase 1現状 | Phase 2ロードマップ |
|-----|----------|-----------|-----------------|
| **Loglass** | 1億円 | AI分析アシスタント、AI予実分析レポート | **1年以内** AIエージェント構想 |
| **DIGGLE** | 不詳 | AIレポート分析（2025年9月～） | **2027年** FP&Aエージェント実現予定 |

**評価**: 国内ベンダーもAI進化の道を歩んでいるが、実装は初期段階 → **貴プロジェクトには十分な機会がある**

### 海外BIツール（Power BI、Tableau、ThoughtSpot）の進化

**共通パターン**: セマンティックレイヤー × LLM = 自然言語から正確なデータ抽出

**先進技術**:
- **ThoughtSpot Spotter**: SQL精度100%達成（BARQ技術）
- **Tableau Agent**: 完全なエージェント型AIへ進化
- **Looker Gemini**: BigQuery × Vertex AI ネイティブ統合

**教訓**: セマンティックレイヤー（ビジネス用語定義の一元管理）がAI精度を左右する

---

## Part 2: Deep Researchの主要統計

### ROI実績（実装済みベンダーより）

| KPI | 改善度 | 企業事例 |
|-----|--------|---------|
| **予測精度** | 20-25%向上 | Oracle: 25%改善、Coca-Cola: 20%改善（Anaplan） |
| **計画サイクル短縮** | 40-60%削減 | Oracle Japan: 計画サイクル60%短縮 |
| **工数削減** | 30-80%削減 | Loglass: 予算策定30%削減、Shutterstock: 10,000時間/年 |
| **クローズ期間** | 50%削減 | Oracle: 10日→5日、Endeavour Energy: 予測誤差6%→2% |

### 市場規模
- **EPM市場**: 2024年 $70億 → 2029年 $94億（CAGR 5.9%）
- **AI導入率（財務部門）**: 2023年 37% → 2024年 58% → 2026年予測 90%
- **日本の導入率**: 47%（グローバルより15-20ポイント低い）

### LLM技術コスト推移
- **推論価格**: 年間中央値 **50倍低下**
- **GPT-4o**: $60→$10/M tokens（83%減）
- **DeepSeek**: 業界標準比 **90%安価**

### データ品質の課題（BCG調査）
- 74%の企業がAIの価値創出・スケール化に苦戦
  - 70%が「人・プロセス」関連課題
  - 20%が技術問題
  - 10%がアルゴリズム問題

---

## Part 3: プロダクト戦略との整合性

### product.md に定義された Phase 1-4 AI戦略との対応

| Phase | 目的 | 本ロードマップの位置づけ |
|-------|------|----------------------|
| **Phase 1** | AIレディな基盤構築 | ← **本ロードマップで実装すべき部分** |
| **Phase 2** | 分析補助AI | → 本ロードマップの P1/P2 機能 |
| **Phase 3** | 仮説・打ち手支援 | → 本ロードマップの P2/P3 機能 |
| **Phase 4** | 戦略的経営管理AI | → 中期（2027年以降） |

**product.md の AIに関する基本方針（遵守必須）:**
- AIは意思決定の主体ではない → 思考の補助・拡張のみ
- 正本データ（SSoT）に基づく
- 推論根拠・参照データを説明できる
- ブラックボックス化しない

---

## Part 4: 実装ロードマップ（全体像）

### 優先度マトリクス：10大AI機能

| 優先度 | 機能 | Phase | 複雑度 | ROI | 実装週 | 本質的理由 |
|--------|------|-------|--------|-----|-------|----------|
| **P0-1** | **異常値自動検知** | 1A | 🟢 低 | 中 | Weeks 7-9 | 最も簡単、データ品質改善 |
| **P0-2** | **予実差異AI解説（日本語）** | 1B | 🟡 中 | **高** | Weeks 7-10 | 最高需要、差別化しやすい |
| **P0-3** | **自然言語Q&A (NLQ)** | 1B | 🔴 高 | **高** | Weeks 8-12 | テーブルステークス化 |
| P1-4 | グラフ自動生成 | 1C | 中 | 中 | Weeks 13-16 | UX価値、既存インフラ活用 |
| P1-5 | チャットボット | 1C | 高 | 中 | Weeks 17-20 | 多機能統合、閉じたループ |
| P2-6 | ドライバー分析 | 2 | 中 | 高 | 後続 | 差異の「なぜ」説明 |
| P2-7 | 売上ML予測 | 2 | 高 | 高 | 後続 | 精度25%向上実績 |
| P2-8 | レポート自動生成 | 2 | 中 | 高 | 後続 | 工数30%削減実績 |
| P3-9 | シナリオ比較機能 | 3 | 高 | 中 | 後続 | What-if分析ニーズ |
| P4-10 | 経営参謀Bot（エージェント） | 4 | 最高 | 最高 | 2027+ | 自律的提案（Proactive） |

---

## Part 5: 実装フェーズ詳細（CCSDD準拠）

### PHASE 1A: 基盤構築（Weeks 1-6）— 必須・ブロッキング

#### 🔴 Critical Path: 以下3つは全て必須で、順序が重要

**Week 1-3: Semantic Layer（セマンティックレイヤー）**
- **Why**: NLQ、RAG、エンティティ解決が全て依存
- **Spec**: `/kiro:spec-init "ai/_shared/semantic-layer"`
- **成果物**:
  - subjects/departments/metrics の metadata 拡張
  - PeriodResolver サービス（「今期」「前年同期」→ fiscal_year + period_no）
  - AI用JSONスキーマ エクスポート
- **実装難度**: 🟢 低（既存メタデータを構造化するだけ）
- **所要人数**: 1 Backend Engineer, 0.5 AI Engineer

**Week 2-4: AI Entities（データベース）**
- **Why**: 会話履歴、RAGベクトル、監査ログ、異常検知結果を保存
- **Spec**: `/kiro:spec-init "ai/_shared/entities"`
- **テーブル追加**:
  - `ai_conversations` (session + multi-turn history)
  - `ai_knowledge_base` (pgvector embeddings)
  - `ai_audit_logs` (query, response, cost, feedback)
  - `ai_anomaly_alerts` (threshold violations)
- **RLS設定**: tenant_id による行レベルセキュリティ（必須）
- **実装難度**: 🟢 低（Prisma schema + migrations）
- **所要人数**: 1 Backend Engineer

**Week 3-5: LLM Service Adapter（API層）**
- **Why**: 全AI機能が LLM API 呼び出しに依存
- **Spec**: `/kiro:spec-init "ai/_shared/llm-service"`
- **実装内容**:
  - Claude 3.5 Sonnet API 統合 (@anthropic-ai/sdk)
  - OpenAI API フォールバック
  - Request/Response ロギング（コスト追跡）
  - トークン計数、リトライロジック
- **実装難度**: 🟢 低（Adapter パターン）
- **所要人数**: 1 Backend Engineer

**Phase 1A の成果**: AI機能が「読み込める」ようになる（データ品質が担保される）

---

### PHASE 1B: P0 Features（Weeks 7-16）— 可能な限り並行実行

#### 機能1️⃣: 異常値自動検知（Weeks 7-9） ⭐ 最速

**Why First?**
- 実装が簡潔（ルールベース、LLMなし）
- ユーザー価値が高い（データ入力ミス防止）
- 他機能の足がかりにならない

**Spec**: `/kiro:spec-init "ai/anomaly-detection"`

**ビジネスルール**:
```
- 前月比 ±30% を超える変動
- 予算比 ±20% を超える差異
- 前年比 ±50% を超える乖離
- 負の値（あり得ない値）
- 重複データ
```

**データフロー**:
```
fact_amounts 入力 → AnomalyDetector → ai_anomaly_alerts 保存 → UI通知
```

**実装難度**: 🟢 低（状態変更フック + 簡単な計算）

**ROI**: CFOの 51% がデータ品質に課題、この機能で改善

**成果物**:
- AnomalyDetectionService（Domain API）
- AnomalyAlertsController（BFF）
- AlertsList UI コンポーネント

---

#### 機能2️⃣: 予実差異AI解説（Weeks 7-10）⭐ 最高ROI

**Why Next?**
- 最高の需要（月次決算後に必須）
- 差別化しやすい（日本語、FP&A特化）
- グローバル勢は日本語対応が甘い

**Spec**: `/kiro:spec-init "ai/variance-analysis"`

**ビジネスフロー**:
```
Period Close 後、CFO が Dashboard 開く
  ↓
「AI分析」ボタン クリック
  ↓
API: Top 10-20 差異を自動抽出
  ↓
Semantic Layer で「何が動いたか」を理解
  ↓
RAG で過去のコメント検索（同じ差異の根本原因）
  ↓
Claude が仮説生成 + トレンド分析
  ↓
Markdown レポート出力
```

**AI プロンプト設計**:
```
"以下の差異データと過去の分析コメントを参考に、
 差異の原因仮説を3つ提示してください。
 各仮説について根拠と信頼度（%）を明記してください。"
```

**実装難度**: 🟡 中（Query Planner + RAG + Prompt Engineering）

**成果物**:
- VarianceAnalysisService
- VarianceQueryPlanner（差異の自動抽出）
- RAG 統合（pgvector + semantic search）
- VarianceReportController（BFF）
- VarianceReport 表示 UI

**期待効果**:
- 月次分析時間 30-80% 削減
- AI仮説の採用率 > 80%（内容的正確性）

---

#### 機能3️⃣: 自然言語Q&A (NLQ)（Weeks 8-12）⭐ テーブルステークス

**Why Important?**
- 全ベンダーが実装済み（テーブルステークス化）
- ユーザーの期待値が高い
- 複雑度が最高（Intent→Entity→QueryPlan→Execute→Format）

**Spec**: `/kiro:spec-init "ai/nlq"`

**対応パターン（Week 1優先）**:
```
1. 「今期着地は？」→ Latest period, all subjects
2. 「9月の売上高は？」→ Specific period, specific metric
3. 「前年比は？」→ Current vs previous fiscal year
4. 「予算との差異は？」→ Budget vs actual
5. 「X部門の営業利益は？」→ Specific dept, specific KPI
```

**AI アーキテクチャ**:
```
Query (日本語)
  ↓
IntentClassifier → Intent (「利益確認」「比較」「トレンド」など)
  ↓
EntityExtractor → 部門・期間・科目 抽出（Semantic Layerが支援）
  ↓
QueryPlanner → SQL-like 中間形式に変換
  ↓
QueryExecutor → fact_amounts から実行 + 計算
  ↓
ResponseFormatter (Claude) → 日本語で自然な回答 + データ表示
```

**実装難度**: 🔴 高（5 つのコンポーネント、複数の判断ロジック）

**成果物**:
- NlqIntentClassifier
- NlqEntityExtractor
- NlqQueryPlanner
- NlqQueryExecutor
- NlqResponseFormatter
- SessionManager（多ターン対応）
- ChatWidget UI

**期待効果**:
- 85-90% の一般的クエリが自動応答（Planful実績）
- IT 依頼削減
- テーブル + グラフ の自動生成

---

### PHASE 1C: P1 Features（Weeks 13-20）— 時間があれば

#### 機能4️⃣: グラフ自動生成（Weeks 13-16）

**Why P1?**
- P0 機能（NLQ、Variance）の完成度を高める
- 既存 Dashboard の SyncFusion インフラを活用可能
- ユーザー体験の向上だが、ビジネス価値は中程度

**Spec**: `/kiro:spec-init "ai/graph-generation"`

**ビジネスロジック**:
```
Query データ形式を分析 →
  - 2+ series → Line Chart
  - Categories → Bar Chart
  - 1 value → KPI Card
  - Composition → Pie Chart
→ Chart config 出力
```

**実装難度**: 🟡 中

**成果物**:
- ChartTypeSelector
- GraphGenerationService
- Recharts 互換出力

---

#### 機能5️⃣: Executive Chat Bot（Weeks 17-20）

**Why P1 Closing?**
- 全 P0 機能を統合（NLQ + Variance + Graph）
- 多ターン会話、プロアクティブ提案
- ユーザー習慣形成に重要

**Spec**: `/kiro:spec-init "ai/chat-bot"`

**機能**:
```
Q: 「9月の利益が前月比で下がった理由は？」
Claude: 「原因は 3 つ考えられます：
  1. COGS が 15% 上昇（原材料費↑）→ 確度 75%
  2. 販売数が 8% 減少（市場需要↓）→ 確度 70%
  3. 販管費が 5% 増加（一時的な広告出稿）→ 確度 85%
  データ: [graph] [table]」

ユーザー: 「対策案は？」
Claude: 「過去の同様ケースから：
  - A社は原材料仕入先を変更→ 3 月で COGS 12% 改善
  - B社は需要喚起キャンペーン実施→ 2 ヶ月で売上 15% 回復」
```

**実装難度**: 🔴 高（複数エージェント協調、状態管理）

---

## Part 6: CCSDD 仕様化タスク（実行順序）

### 即開始すべき作業（This Week）

```
Week 1 開始：

✅ Step 1: Specification 仕様化
  → /kiro:spec-init "ai/_shared/semantic-layer"
  → /kiro:spec-requirements "ai/_shared/semantic-layer"

✅ Step 2: Contract 確認
  → packages/contracts/src/bff/ai/index.ts を監査
  → 不足があれば追加仕様化

✅ Step 3: Design Review
  → /kiro:spec-design "ai/_shared/semantic-layer"
  → デザインレビュー実施（Steering に沿うか確認）

✅ Step 4: Task 分解
  → /kiro:spec-tasks "ai/_shared/semantic-layer"
  → 実装タスクへ
```

### 完全な仕様化シーケンス

**Phase 1A (Weeks 1-6 仕様化)**
```
Week 1:
  /kiro:spec-init "ai/_shared/semantic-layer"
  /kiro:spec-requirements "ai/_shared/semantic-layer"
  /kiro:spec-design "ai/_shared/semantic-layer"
  /kiro:spec-tasks "ai/_shared/semantic-layer"

Week 2:
  /kiro:spec-init "ai/_shared/entities"
  /kiro:spec-requirements "ai/_shared/entities"
  /kiro:spec-design "ai/_shared/entities"
  /kiro:spec-tasks "ai/_shared/entities"

Week 3:
  /kiro:spec-init "ai/_shared/llm-service"
  /kiro:spec-requirements "ai/_shared/llm-service"
  /kiro:spec-design "ai/_shared/llm-service"
  /kiro:spec-tasks "ai/_shared/llm-service"
```

**Phase 1B (Weeks 4-6 仕様化, Weeks 7-16 実装)**
```
Week 4:
  /kiro:spec-init "ai/anomaly-detection"
  /kiro:spec-requirements "ai/anomaly-detection"
  /kiro:spec-design "ai/anomaly-detection"
  /kiro:spec-tasks "ai/anomaly-detection"

Week 5:
  /kiro:spec-init "ai/variance-analysis"
  /kiro:spec-requirements "ai/variance-analysis"
  /kiro:spec-design "ai/variance-analysis"
  /kiro:spec-tasks "ai/variance-analysis"

Week 6:
  /kiro:spec-init "ai/nlq"
  /kiro:spec-requirements "ai/nlq"
  /kiro:spec-design "ai/nlq"
  /kiro:spec-tasks "ai/nlq"
```

---

## Part 7: データコントラクト（必須）

### packages/contracts/src/bff/ai/ に必要な型定義

**必須確認項目**:
- [ ] `VarianceReportRequestDto` / `VarianceReportResponseDto`
- [ ] `NlqQueryRequestDto` / `NlqQueryResponseDto`
- [ ] `AnomalyAlertDto` / `AnomalyAlertsResponseDto`
- [ ] `GraphGenerationRequestDto` / `GraphGenerationResponseDto`
- [ ] `ChatBotMessageRequestDto` / `ChatBotMessageResponseDto`
- [ ] `PeriodDto`, `DepartmentDto`, `SubjectDto`（基本型）

**現在の状態確認**:
```bash
# プロジェクトルートで実行
find packages/contracts/src/bff/ai -type f -name "*.ts" | head -20
```

### データベーススキーマ（Prisma）

**追加すべきモデル** (packages/db/prisma/schema.prisma):
```prisma
// AI会話履歴
model ai_conversation {
  id                String @id @default(cuid())
  tenant_id         String
  user_id           String
  session_id        String
  messages          Json   // { role, content, timestamp }[]
  created_at        DateTime @default(now())
  updated_at        DateTime @updatedAt

  @@index([tenant_id, session_id])
}

// RAG用ベクトル
model ai_knowledge_base {
  id                String @id @default(cuid())
  tenant_id         String
  source_type       String // "comment", "report", "meeting_note"
  source_id         String
  content           String
  embedding         Vector(1536) // pgvector
  created_at        DateTime @default(now())

  @@index([tenant_id])
}

// AI監査ログ（コスト追跡）
model ai_audit_log {
  id                String @id @default(cuid())
  tenant_id         String
  user_id           String
  feature           String // "nlq", "variance_analysis", etc.
  query             String
  response          String
  model             String
  input_tokens      Int
  output_tokens     Int
  cost_jpy          Float
  created_at        DateTime @default(now())

  @@index([tenant_id, created_at])
}

// 異常検知アラート
model ai_anomaly_alert {
  id                String @id @default(cuid())
  tenant_id         String
  company_id        String
  period_no         Int
  subject_code      String
  anomaly_type      String // "threshold_violation", "duplicate", "negative_value"
  severity          String // "high", "medium", "low"
  expected_value    Float
  actual_value      Float
  rule_name         String
  status            String // "open", "confirmed", "ignored"
  confirmed_by      String?
  notes             String?
  created_at        DateTime @default(now())

  @@index([tenant_id, status, created_at])
}
```

---

## Part 8: 技術スタック推奨

### LLM選定

**推奨**: Claude 3.5 Sonnet
```
理由:
- 日本語品質が最高
- 複雑な推論能力（金融分析）
- コスト効率良好
- Context Window 大（200K tokens）
```

**フォールバック**: GPT-4o
```
理由:
- コスト最適化時
- Claude API 障害時
```

### 埋め込みモデル（RAG用）
- **推奨**: text-embedding-3-large (OpenAI)
- **理由**: 多言語対応、品質、コスト効率

### ベクトルDB
- **推奨**: PostgreSQL pgvector
- **理由**: 既存インフラ活用、追加コスト不要、RLS 対応可能

### 監視・ロギング
- **推奨**: ai_audit_logs テーブル + Grafana
- **目的**: コスト追跡、品質監視、コンプライアンス

---

## Part 9: チーム構成 & 工数見積

### Phase 1A Foundation (Weeks 1-6 実装)
- **1x Backend Engineer** (FT) = 1.5 PW
- **0.5x Prompt Engineer** (PT) = 0.25 PW
- **Total**: 2 PW

### Phase 1B P0 Features (Weeks 7-16)
- **2x Backend Engineers** (FT) = 4 PW
- **1x Frontend Engineer** (FT) = 2.5 PW
- **0.5x Prompt Engineer** (PT) = 1 PW
- **Total**: 7.5 PW

### Phase 1C P1 Features (Weeks 13-20, 並行)
- **2x Backend Engineers** = 2 PW
- **1x Frontend Engineer** = 1.5 PW
- **0.5x Prompt Engineer** = 0.5 PW
- **Total**: 4 PW

**全体**: 13.5 PW（6-8 名チーム, 20 週）

---

## Part 10: リスク管理 & 対策

### リスク: LLM のハルシネーション（幻覚）

**対策**:
- Human-in-the-loop を必須化（AI 出力は提案、確定は人）
- 信頼度スコア表示
- RAG で根拠データを常に提示
- Monthly Prompt Audit（品質低下を検知）

### リスク: データ品質不足

**対策**:
- 異常検知機能で入力ミス削減
- Semantic Layer の充実（メタデータ整備）
- Data Quality Dashboard 構築

### リスク: 競合の開発加速

**対策**:
- 差別化機能に集中（日本語、J-SOX対応、Excel互換）
- 高速反復（毎月フィーチャーリリース）
- ユーザーフィードバック即時反映

### リスク: LLM コスト変動

**対策**:
- マルチ LLM 対応（OpenAI 並行）
- Token 計数 + Cost Cap 設定
- DeepSeek など安価モデルの検証

### リスク: 規制強化

**対策**（J-SOX改正対応）:
- AI 出力の監査証跡を設計段階で組込
- Glass Box AI（説明可能性）を優先
- 意思決定権は常に人に帰属

---

## Part 11: 成功指標 & KPI

### Phase 1A Foundation
- ✅ Semantic Layer カバー率 = 100%（全 Subject, Department, Metric）
- ✅ PeriodResolver 精度 = 100%（20 パターンのテスト通過）
- ✅ AI Entities = RLS 有効化確認

### Phase 1B P0 Features

**異常検知**:
- ユーザー採用率 > 70%
- 偽陽性率 < 10%
- データ入力ミス検出率 > 90%

**予実差異分析**:
- AI 仮説の人による採用率 > 80%
- レスポンス時間 < 3 秒
- レポート生成時間 短縮度 > 30%

**NLQ**:
- トップ 10 パターン成功率 > 80%
- レスポンス時間 < 5 秒
- ユーザー満足度 (NPS) > 40

### Phase 1C P1 Features

**グラフ自動生成**:
- 4 チャートタイプ正答率 > 90%
- ユーザー満足度 > 80%

**チャットボット**:
- 多ターン会話継続率 > 60%（3 ターン以上）
- 提案の実行率 > 50%

---

## Part 12: 競争力分析

### vs グローバル大手（Oracle, SAP, Anaplan）

| 観点 | 彼ら | 貴プロジェクト | 勝ちの条件 |
|------|------|---------------|----------|
| **機能の充実度** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | 数では負けない = コアに特化 |
| **日本語対応** | ⭐⭐ | ⭐⭐⭐⭐⭐ | **日本語 Native の質** |
| **日本会計対応** | ⭐ | ⭐⭐⭐⭐⭐ | J-SOX、連結対応 |
| **説明可能性** | ⭐⭐⭐ | ⭐⭐⭐⭐ | Glass Box AI |
| **Excel統合** | ⭐⭐ | ⭐⭐⭐⭐⭐ | 既存資産保護 |

### vs 国内ベンダー（Loglass, DIGGLE）

| 観点 | Loglass | DIGGLE | 貴プロジェクト |
|------|---------|--------|-------------|
| **AI化の進行度** | 分析補助AI | 分析補助AI → エージェント計画中 | **最初からエージェント設計** |
| **機能数** | 豊富 | 豊富 | コア機能に絞るが品質高い |
| **実装段階** | 本番稼働中 | 公開間もない | **今から実装できる = 最新技術採用可** |

**戦略的ポジション**: 「国内ベンダーとグローバル大手の中間に位置する、日本特化型のAgentic EPM」

---

## Part 13: 実行ガイドライン（明日から）

### この 1 週間でやること

**1. Steering 再確認**
- [ ] product.md の Phase 1-4 AI戦略を再確認
- [ ] tech.md の Multi-Tenant / RLS 要件を再確認
- [ ] development-process.md の CCSDD workflow を頭に叩き込む

**2. 現状監査**
- [ ] packages/contracts/src/bff/ai/ の状態確認
  ```bash
  ls -la packages/contracts/src/bff/ai/
  ```
- [ ] 既存 AI 仕様があるか確認
  ```bash
  find .kiro/specs -name "*ai*" -type d
  ```

**3. チームアライン**
- [ ] このドキュメントをチーム全体で共有・議論
- [ ] Phase 1A（6週間）の Semantic Layer を最優先に同意取得
- [ ] Prompt Engineer の確保（0.5-1 FTE）

**4. 仕様化開始**
- [ ] Week 1 開始時点で以下を実行:
  ```
  /kiro:spec-init "ai/_shared/semantic-layer"
  /kiro:spec-requirements "ai/_shared/semantic-layer"
  ```

### Build vs Partner vs Buy の判断基準

| 領域 | 判断 | 理由 |
|------|------|------|
| **セマンティックレイヤー** | Build | コア競争力、カスタマイズ必要 |
| **LLM 基盤** | Partner (Azure OpenAI) | 開発効率、セキュリティ |
| **RAG エンジン** | Build + OSS (pgvector) | インフラコスト削減 |
| **チャートライブラリ** | Buy/Partner (Recharts) | 開発期間短縮 |
| **外部データ連携** | Partner (SPEEDIA等) | データ調達コスト削減 |

---

## Part 14: 最後に—プロダクト戦略への寄与

このロードマップを実行することで:

✅ **Phase 1 完成**: AIレディなEPM基盤が完成
✅ **市場投入**: グローバル勢も国内勢も持たない「日本語AIエージェントEPM」の完成
✅ **競争優位**: セマンティックレイヤー × 説明可能性 × Excel互換性という差別化軸
✅ **スケーラビリティ**: Phase 2-4 への道が明らかになる

**2026年末時点での目標像:**
- 予実差異分析の 80% が AI 補助で実施可能
- NLQ で CFO が「SQL 不要」に
- 異常検知で月次締めの期間短縮
- ChatBot で 24/7 財務相談が可能

**これが実現できれば、Loglass や DIGGLE に対して明確な差別化が成立する。**

---

## References & Links

- 詳細分析: `.kiro/specs/仕様検討/20260128_生成AI機能の機能検討のためのDeepReaserch結果`
- プロダクト戦略: `.kiro/steering/product.md`
- 開発規約: `.kiro/steering/development-process.md`
- 技術仕様: `.kiro/steering/tech.md`
- 構造規約: `.kiro/steering/structure.md`

---

**Document Status**: APPROVED FOR IMPLEMENTATION
**Next Action**: `/kiro:spec-init "ai/_shared/semantic-layer"` を実行（Week 1）
